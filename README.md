# E-Commerce Data Pipeline Platform

A production-ready, scalable data pipeline platform for e-commerce analytics, demonstrating modern data engineering practices with Apache Spark, Kafka, Airflow, and PostgreSQL.

![Architecture](docs/architecture.png)

## ğŸ—ï¸ Architecture Overview
text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        E-Commerce Data Pipeline Platform                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚   REST API   â”‚     â”‚   CSV Files  â”‚     â”‚  PostgreSQL  â”‚                     â”‚
â”‚  â”‚   (Orders)   â”‚     â”‚  (Products)  â”‚     â”‚  (Customers) â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚         â”‚                    â”‚                    â”‚                             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                              â–¼                                                  â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚                    â”‚   Apache Kafka   â”‚                                         â”‚
â”‚                    â”‚  (Message Queue) â”‚                                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚                             â”‚                                                   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚              â–¼              â–¼              â–¼                                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚     â”‚   Batch    â”‚  â”‚  Streaming â”‚  â”‚   Data     â”‚                              â”‚
â”‚     â”‚ Processing â”‚  â”‚ Processing â”‚  â”‚  Quality   â”‚                              â”‚
â”‚     â”‚  (Spark)   â”‚  â”‚  (Spark)   â”‚  â”‚  Checks    â”‚                              â”‚
â”‚     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚           â”‚               â”‚               â”‚                                     â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                           â–¼                                                     â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚                  â”‚   Data Lake     â”‚                                            â”‚
â”‚                  â”‚   (MinIO/S3)    â”‚                                            â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚                           â”‚                                                     â”‚
â”‚                           â–¼                                                     â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚                  â”‚ Data Warehouse  â”‚                                            â”‚
â”‚                  â”‚ (PostgreSQL DW) â”‚                                            â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚                           â”‚                                                     â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚           â–¼               â–¼               â–¼                                     â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚     â”‚  Grafana â”‚   â”‚  Metabaseâ”‚   â”‚Apache Airflowâ”‚                              â”‚
â”‚     â”‚(Monitor) â”‚   â”‚   (BI)   â”‚   â”‚(Orchestrate) â”‚                              â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. æ•´é«”æµç¨‹æ¦‚è¿°

è³‡æ–™ä¾†æºï¼ˆIngestion Layerï¼‰ï¼šå¾å¤šç¨®ä¾†æºæ“·å–è³‡æ–™ï¼ŒåŒ…æ‹¬ REST APIï¼ˆè¨‚å–®ï¼‰ã€CSV æª”æ¡ˆï¼ˆç”¢å“ï¼‰å’Œ PostgreSQL è³‡æ–™åº«ï¼ˆå®¢æˆ¶ï¼‰ã€‚é€™äº›ä¾†æºä»£è¡¨çµæ§‹åŒ–ã€åŠçµæ§‹åŒ–èˆ‡æª”æ¡ˆå‹è³‡æ–™ï¼Œé€é Apache Kafka ä½œç‚ºè¨Šæ¯ä½‡åˆ—ï¼ˆMessage Queueï¼‰çµ±ä¸€åŒ¯å…¥ï¼Œå¯¦ç¾å³æ™‚èˆ‡æ‰¹æ¬¡è³‡æ–™æµã€‚
è™•ç†å±¤ï¼ˆProcessing Layerï¼‰ï¼šè³‡æ–™é€²å…¥ Kafka å¾Œï¼Œåˆ†ç‚ºä¸‰å€‹ä¸¦è¡Œåˆ†æ”¯ï¼š
Batch Processingï¼ˆæ‰¹æ¬¡è™•ç†ï¼Œä½¿ç”¨ Sparkï¼‰ã€‚
Streaming Processingï¼ˆä¸²æµè™•ç†ï¼Œä½¿ç”¨ Sparkï¼‰ã€‚
Data Quality Checksï¼ˆè³‡æ–™å“è³ªæª¢æŸ¥ï¼‰ã€‚
é€™å±¤ç¢ºä¿è³‡æ–™åœ¨é€²å…¥å„²å­˜å‰é€²è¡Œè½‰æ›ã€æ¸…æ´—èˆ‡é©—è­‰ã€‚

å„²å­˜å±¤ï¼ˆStorage Layerï¼‰ï¼šè™•ç†å¾Œçš„è³‡æ–™å…ˆå­˜å…¥ Data Lakeï¼ˆä½¿ç”¨ MinIO æˆ– S3 ä½œç‚ºç‰©ä»¶å„²å­˜ï¼‰ï¼Œå†è¼‰å…¥ Data Warehouseï¼ˆPostgreSQL DWï¼‰ã€‚é€™é«”ç¾æ¹–å€‰ä¸€é«”ï¼šæ¹–ä½œç‚ºåŸå§‹/å¤§è¦æ¨¡å„²å­˜ï¼Œå€‰ä½œç‚ºç²¾ç…‰/åˆ†æå„²å­˜ã€‚
æ¶ˆè²»å±¤ï¼ˆConsumption Layerï¼‰ï¼šå¾å€‰å„²è¼¸å‡ºåˆ°ä¸‰å€‹å·¥å…·ï¼š
Grafanaï¼ˆç›£æ§ï¼‰ã€‚
Metabaseï¼ˆBI åˆ†æèˆ‡è¦–è¦ºåŒ–ï¼‰ã€‚
Apache Airflowï¼ˆç·¨æ’èˆ‡èª¿åº¦æ•´å€‹ç®¡é“ï¼‰ã€‚
æ•´é«”æ˜¯ç«¯åˆ°ç«¯çš„è³‡æ–™ç®¡é“ï¼Œå¾ä¾†æºåˆ°åˆ†æï¼Œå½¢æˆé–‰ç’°ã€‚é€™å€‹æ–¹æ¡ˆå¼·èª¿å¯æ“´å±•æ€§èˆ‡é–‹æºï¼Œç¬¦åˆ 2026 å¹´ä¸»æµæ¹–å€‰è¶¨å‹¢ï¼ˆå¦‚ä½¿ç”¨ MinIO æ¨¡æ“¬ S3ï¼Œé¿å…é›²ç«¯é–å®šï¼‰ã€‚


2. æ¹–å€‰ä¸€é«”çš„ç‰¹é»åœ¨åœ–ä¸­çš„é«”ç¾

è³‡æ–™æ¹–ï¼ˆData Lakeï¼‰ï¼šä½æ–¼ä¸­é–“ï¼Œä½¿ç”¨ MinIO/S3 ä½œç‚ºæ ¸å¿ƒå„²å­˜ã€‚é€™æ˜¯æ¹–çš„éƒ¨åˆ†ï¼Œæ”¯æ´åŸå§‹è³‡æ–™çš„ä½æˆæœ¬å­˜æ”¾ï¼ˆSchema-on-Readï¼‰ï¼Œé©åˆ PB ç´šå¤šæ ¼å¼è³‡æ–™ï¼ˆå¦‚è¨‚å–® JSONã€ç”¢å“ CSVï¼‰ã€‚å®ƒä½œç‚ºä¸­é–“å±¤ï¼Œå…è¨±å½ˆæ€§æ“´å±•ï¼Œé¿å…ç›´æ¥è² è¼‰åˆ°å€‰å„²ã€‚
è³‡æ–™å€‰å„²ï¼ˆData Warehouseï¼‰ï¼šä½¿ç”¨ PostgreSQL DW ä½œç‚ºä¸‹æ¸¸ï¼Œå°ˆæ³¨çµæ§‹åŒ–æŸ¥è©¢èˆ‡ BIã€‚é€™æ˜¯å€‰çš„éƒ¨åˆ†ï¼Œæä¾› Schema-on-Writeã€ACID äº¤æ˜“èˆ‡é«˜æ•ˆ SQL åˆ†æã€‚
æ•´åˆæ©Ÿåˆ¶ï¼šæ¹–å€‰é€éè™•ç†å±¤é€£æ¥ï¼ŒSpark è² è²¬å¾æ¹–ä¸­è®€å–/å¯«å…¥è³‡æ–™åˆ°å€‰ä¸­ã€‚é›–ç„¶åœ–ä¸­æœªæ˜ç¢ºæåŠé–‹æ”¾è¡¨æ ¼æ ¼å¼ï¼ˆå¦‚ Iceberg æˆ– Delta Lakeï¼‰ï¼Œä½†åœ¨å¯¦ä½œä¸­å¯è¼•é¬†æ•´åˆï¼ˆå¦‚ Spark + Delta Lake æ–¼ MinIO ä¸Šï¼‰ï¼Œå¯¦ç¾çœŸæ­£æ¹–å€‰ä¸€é«”çš„ ACID æ”¯æ´ã€æ™‚é–“æ—…è¡Œèˆ‡æ²»ç†ã€‚é€™é¿å…å‚³çµ± ETL çš„è¤‡é›œï¼Œè³‡æ–™å¯åœ¨æ¹–ä¸­ç›´æ¥åˆ†æï¼Œæˆ–ç²¾ç…‰å¾Œç§»åˆ°å€‰ã€‚
å„ªå‹¢ï¼šæˆæœ¬ä½ï¼ˆå…¨é–‹æºï¼‰ã€å½ˆæ€§é«˜ï¼ˆæ‰¹æ¬¡/ä¸²æµä¸¦å­˜ï¼‰ã€æ²»ç†å¥½ï¼ˆå“è³ªæª¢æŸ¥ + ç›£æ§ï¼‰ã€‚æ½›åœ¨ç¼ºé»ï¼šè‹¥ç„¡è¡¨æ ¼æ ¼å¼ï¼Œæ¹–æ˜“è®Šã€Œè³‡æ–™æ²¼æ¾¤ã€ï¼›ä½†å¯æ“´å…… Hudi/Iceberg è§£æ±ºã€‚
å…è²»æ–¹æ¡ˆç›¸ç¬¦ï¼šèˆ‡å…ˆå‰è¨è«–çš„é–‹æºå †ç–Šä¸€è‡´ï¼ˆå¦‚ MinIO + Spark + Airflowï¼‰ï¼Œç„¡éœ€ä»˜è²»é›²æœå‹™ã€‚

3. Spark çš„ä½œç”¨åˆ†æ
Sparkï¼ˆApache Sparkï¼‰åœ¨åœ–ä¸­æ‰®æ¼”æ ¸å¿ƒè™•ç†å¼•æ“ï¼Œå‡ºç¾æ–¼ Batch Processing å’Œ Streaming Processing åˆ†æ”¯ï¼Œæ˜¯æ•´å€‹ç®¡é“çš„ã€Œè³‡æ–™è½‰æ›èˆ‡è¨ˆç®—å¤§è…¦ã€ã€‚ä½œç‚ºé–‹æºåˆ†æ•£å¼è™•ç†æ¡†æ¶ï¼ŒSpark æ”¯æ´å¤§è¦æ¨¡è³‡æ–™æ“ä½œï¼Œå„ªåŒ–è¨˜æ†¶é«”è¨ˆç®—ï¼Œé©åˆå¤§æ•¸æ“šå ´æ™¯ã€‚å…·é«”ä½œç”¨å¦‚ä¸‹ï¼š

æ‰¹æ¬¡è™•ç†ï¼ˆBatch Processingï¼‰ï¼šSpark ç”¨æ–¼å®šæœŸè™•ç†å¤§é‡æ­·å²è³‡æ–™ï¼Œå¦‚æ¯æ—¥èšåˆè¨‚å–®/ç”¢å“è³‡æ–™ã€‚ä½œç”¨åŒ…æ‹¬ï¼š
è®€å– Kafka ä¸­çš„æ‰¹æ¬¡è¨Šæ¯ã€‚
åŸ·è¡Œ ETLï¼ˆExtract-Transform-Loadï¼‰ï¼šæ¸…æ´—ã€èšåˆã€è½‰æ›ï¼ˆå¦‚åˆä½µè¨‚å–®èˆ‡å®¢æˆ¶è³‡æ–™ï¼‰ã€‚
è¼¸å‡ºåˆ° Data Lakeï¼Œæå‡æ•ˆç‡ï¼ˆæ¯”å‚³çµ± Hadoop å¿« 100 å€ï¼‰ã€‚

ä¸²æµè™•ç†ï¼ˆStreaming Processingï¼‰ï¼šSpark Streamingï¼ˆæˆ– Spark Structured Streamingï¼‰è™•ç†å³æ™‚è³‡æ–™æµï¼Œå¦‚å¯¦æ™‚è¨‚å–®æ›´æ–°ã€‚ä½œç”¨åŒ…æ‹¬ï¼š
å¾ Kafka æ¶ˆè²»å³æ™‚è¨Šæ¯ã€‚
é€²è¡Œçª—å£èšåˆã€é€£ç·šæ“ä½œï¼ˆå¦‚å³æ™‚å®¢æˆ¶è¡Œç‚ºåˆ†æï¼‰ã€‚
ç¢ºä¿ä½å»¶é²è¼¸å‡ºåˆ°æ¹–ä¸­ï¼Œæ”¯æ´å®¹éŒ¯èˆ‡æ“´å±•ã€‚

æ•´é«”è²¢ç»ï¼š
æ©‹æ¥æ¹–å€‰ï¼šSpark å¯ç›´æ¥è®€å¯« MinIO/S3ï¼ˆæ¹–ï¼‰å’Œ PostgreSQLï¼ˆå€‰ï¼‰ï¼Œæ•´åˆè¡¨æ ¼æ ¼å¼ï¼ˆå¦‚ Delta Lakeï¼‰æä¾›äº‹å‹™æ”¯æ´ã€‚
èˆ‡å…¶ä»–çµ„ä»¶çš„é—œä¿‚ï¼šå¾ Kafka è¼¸å…¥ï¼Œèˆ‡ Data Quality Checks ä¸¦è¡Œï¼ˆå¯èƒ½ç”¨ Spark SQL é©—è­‰ï¼‰ï¼›Airflow å¯èª¿åº¦ Spark ä»»å‹™ï¼›Grafana å¯ç›£æ§ Spark å¢é›†æ•ˆèƒ½ã€‚
å„ªå‹¢ï¼šçµ±ä¸€å¼•æ“è™•ç†æ‰¹æ¬¡/ä¸²æµï¼Œé¿å…å¤šæ¡†æ¶ç¶­è­·ï¼›æ”¯æ´ Python/Scala/Javaï¼Œæ˜“æ•´åˆ MLï¼ˆå¦‚ Spark MLlib åˆ†æå®¢æˆ¶åå¥½ï¼‰ã€‚
åœ¨æ¹–å€‰ä¸­çš„å®šä½ï¼šSpark æ˜¯æ¨è–¦çš„è™•ç†å±¤å·¥å…·ï¼ˆå¦‚å…ˆå‰å…è²»æ–¹æ¡ˆï¼‰ï¼Œä½¿æ¹–å€‰å¾éœæ…‹å„²å­˜è½‰ç‚ºå‹•æ…‹åˆ†æå¹³å°ã€‚

## âœ¨ Features

### Data Ingestion
- **Multi-source ingestion**: REST APIs, CSV/JSON files, databases
- **Real-time streaming**: Apache Kafka integration
- **Incremental loading**: CDC (Change Data Capture) support
- **Schema validation**: Automatic schema detection and validation

### Data Processing
- **Batch Processing**: Apache Spark for large-scale data processing
- **Stream Processing**: Real-time data processing with Spark Streaming
- **Data Transformations**: Comprehensive ETL transformations
- **Data Enrichment**: Join and enrich data from multiple sources

### Data Quality
- **Automated Checks**: Completeness, accuracy, consistency, timeliness
- **Data Profiling**: Statistical analysis of data characteristics
- **Anomaly Detection**: Identify data quality issues automatically
- **Quality Reports**: Detailed quality metrics and dashboards

### Data Warehouse
- **Star Schema**: Optimized dimensional modeling
- **Slowly Changing Dimensions**: SCD Type 1 and Type 2 support
- **Data Marts**: Pre-aggregated analytics tables
- **Query Optimization**: Materialized views and indexes

### Orchestration & Monitoring
- **Apache Airflow**: DAG-based workflow orchestration
- **Grafana Dashboards**: Real-time pipeline monitoring
- **Alerting**: Automated alerts for pipeline failures
- **Logging**: Centralized logging and audit trails

## ğŸš€ Quick Start

### Prerequisites

- Docker Desktop (4.0+)
- Docker Compose (2.0+)
- 16GB RAM (recommended)
- 50GB free disk space

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/Danielfenghk/ecommerce-data-pipeline.git
cd ecommerce-data-pipeline

2. Start the pipeline
Bash

./scripts/start_pipeline.sh
3. Access the services
Airflow UI: http://localhost:8081 (admin/admin)
Spark Master: http://localhost:8080
Grafana: http://localhost:3000 (admin/admin)
Metabase: http://localhost:3001
MinIO: http://localhost:9001 (minioadmin/minioadmin123)
Running Tests
Bash

./scripts/run_tests.sh