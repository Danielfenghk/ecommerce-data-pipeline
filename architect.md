# E-Commerce Data Pipeline Platform 架構說明

## 🏗️ 整體架構概覽

這是一個生產級的電商資料管道平台，採用現代化的**湖倉一體（Lakehouse）**架構，整合了多種開源技術棧來實現端到端的資料處理流程。

### 📋 架構層次結構

```
┌─────────────────────────────────────────────────────────────────┐
│                    E-Commerce Data Pipeline Platform             │
├─────────────────────────────────────────────────────────────────┤
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐           │
│  │   REST API   │  │   CSV Files  │  │ PostgreSQL   │           │
│  │   (Orders)   │  │  (Products)  │  │ (Customers)  │           │
│  └──────┬───────┘  └──────┬───────┘  └──────┬───────┘           │
│         │                 │                 │                    │
│         └─────────────────┼─────────────────┘                    │
│                           ▼                                      │
│                 ┌──────────────────┐                            │
│                 │  Apache Kafka    │                            │
│                 │ (Message Queue)  │                            │
│                 └────────┬─────────┘                            │
│                          │                                      │
│            ┌─────────────┼─────────────┐                        │
│            ▼             ▼             ▼                        │
│   ┌────────────┐ ┌────────────┐ ┌────────────┐                  │
│   │   Batch    │ │ Streaming  │ │   Data     │                  │
│   │ Processing │ │ Processing │ │  Quality   │                  │
│   │  (Spark)   │ │  (Spark)   │ │  Checks    │                  │
│   └─────┬──────┘ └─────┬──────┘ └─────┬──────┘                  │
│         │              │              │                         │
│         └──────────────┼──────────────┘                         │
│                        ▼                                        │
│               ┌─────────────────┐                               │
│               │   Data Lake     │                               │
│               │   (MinIO/S3)    │                               │
│               └────────┬────────┘                               │
│                        │                                        │
│                        ▼                                        │
│               ┌─────────────────┐                               │
│               │ Data Warehouse  │                               │
│               │ (PostgreSQL DW) │                               │
│               └────────┬────────┘                               │
│                         │                                        │
│           ┌─────────────┼─────────────┐                         │
│           ▼             ▼             ▼                         │
│  ┌──────────┐  ┌──────────┐  ┌──────────────┐                   │
│  │ Grafana  │  │ Metabase │  │ Apache Airflow │                 │
│  │(Monitor) │  │   (BI)   │  │ (Orchestrate) │                   │
│  └──────────┘  └──────────┘  └──────────────┘                   │
└─────────────────────────────────────────────────────────────────┘
```

## 🗂️ 核心元件詳解

### 1. **資料來源層（Data Sources）**
- **REST API**: 處理即時訂單資料
- **CSV Files**: 產品目錄資料
- **PostgreSQL**: 客戶資料庫
- 支援多種資料格式：結構化、半結構化、檔案型

### 2. **訊息佇列層（Message Queue）**
- **Apache Kafka**: 統一的資料匯流排
- 支援批次和串流處理
- 實現資料來源的解耦

### 3. **處理層（Processing Layer）**
採用**三路並行處理架構**：

#### **批次處理（Batch Processing）**
- 使用 Apache Spark 進行大規模資料處理
- 處理歷史資料聚合
- 每日定時執行

#### **串流處理（Streaming Processing）**
- Spark Structured Streaming
- 處理即時資料流
- 支援低延遲分析

#### **資料品質檢查（Data Quality Checks）**
- 自動化品質驗證
- 完整性、準確性、一致性檢查
- 自訂品質門檻

### 4. **儲存層（Storage Layer）**

#### **資料湖（Data Lake）**
- **技術**: MinIO (S3 相容物件儲存)
- **格式**: Apache Iceberg (開放表格格式)
- **特點**: Schema-on-Read、低成本儲存

#### **資料倉儲（Data Warehouse）**
- **技術**: PostgreSQL
- **特點**: Schema-on-Write、ACID 事務、高效能查詢

### 5. **消費層（Consumption Layer）**

#### **監控（Monitoring）**
- **Grafana**: 即時管道監控和儀表板

#### **商業智慧（BI）**
- **Metabase**: 互動式分析和視覺化

#### **編排（Orchestration）**
- **Apache Airflow**: DAG-based 工作流程編排

## 🏛️ Lakehouse 架構實現

### **三層架構模式**：

#### **Bronze Layer（青銅層）**
- 原始資料層
- 完整保留來源資料
- 加入中繼資料欄位（`_ingested_at`, `_source`, `_batch_id`）
- 使用 Iceberg 表格格式

#### **Silver Layer（銀層）**
- 清理資料層
- 資料清洗、標準化、去重複
- 商業邏輯驗證

#### **Gold Layer（金層）**
- 聚合資料層
- 維度表（dim_customers, dim_products）
- 事實表（fact_orders）
- 商業指標聚合

### **技術棧特點**：
- **開源優先**: 全技術棧使用開源元件
- **雲端相容**: MinIO 相容 S3 API
- **可擴展**: Spark 分散式處理
- **治理完善**: Iceberg 提供 ACID、時間旅行、模式演進

## 🔄 資料流程

1. **擷取**: 多來源資料經 Kafka 統一匯入
2. **處理**: Spark 進行批次/串流處理 + 品質檢查
3. **儲存**: 湖倉分層儲存（Lakehouse）
4. **消費**: 通過 BI 工具進行分析和視覺化
5. **監控**: Airflow 編排整個流程，Grafana 監控效能

## 🎯 專案亮點

- **生產就緒**: 完整的錯誤處理、重試機制、健康檢查
- **可觀測性**: 詳細的日誌、指標收集、品質報告
- **現代化**: 採用 2024 年主流的 Lakehouse 架構
- **開發友好**: 完整的測試覆蓋、CI/CD 支援

這個架構完美展示了現代資料工程的最佳實踐，特別適合電商場景的複雜資料處理需求。
